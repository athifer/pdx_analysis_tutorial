{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c91f5b59",
   "metadata": {},
   "source": [
    "# PDX Integrated Analysis\n",
    "\n",
    "This notebook demonstrates how to integrate multiple data types (tumor volumes, gene expression, and variants) for comprehensive PDX analysis and biomarker discovery.\n",
    "\n",
    "## Learning Objectives\n",
    "- Integrate multi-modal PDX data\n",
    "- Identify molecular determinants of drug response\n",
    "- Create integrated visualizations\n",
    "- Build predictive models using combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"Seaborn: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841009ec",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Integration\n",
    "\n",
    "Load all three data types and prepare them for integrated analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece36b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tumor volume data\n",
    "try:\n",
    "    # Try realistic data first (recommended)\n",
    "    tumor_df = pd.read_csv('../data/tumor_volumes_realistic.csv')\n",
    "    print(\"✓ Loaded realistic tumor volume data\")\n",
    "except FileNotFoundError:\n",
    "    # Fallback to effective data\n",
    "    try:\n",
    "        tumor_df = pd.read_csv('../data/tumor_volumes_effective.csv') \n",
    "        print(\"✓ Loaded effective tumor volume data\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Error: No tumor volume data found. Please run:\")\n",
    "        print(\"python ../src/python/generate_realistic_pdx_data.py\")\n",
    "        raise\n",
    "\n",
    "print(f\"Tumor data shape: {tumor_df.shape}\")\n",
    "tumor_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a672ba",
   "metadata": {},
   "source": [
    "## 2. Response Metric Calculation\n",
    "\n",
    "Calculate treatment response metrics for each PDX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30924206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load realistic gene expression data\n",
    "expression_file = '../data/expression_tpm_realistic.csv'\n",
    "try:\n",
    "    expr_df = pd.read_csv(expression_file)\n",
    "    print(\"✅ Loaded realistic expression data\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: Realistic expression data not found at {expression_file}\")\n",
    "    print(\"Please run: python ../src/python/generate_realistic_pdx_data.py\")\n",
    "    raise\n",
    "\n",
    "print(f\"Expression data shape: {expr_df.shape}\")\n",
    "print(f\"Genes: {expr_df.shape[1]-1}, Samples: {expr_df.shape[0]}\")\n",
    "expr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26273277",
   "metadata": {},
   "source": [
    "## 3. Gene Expression Analysis\n",
    "\n",
    "Identify genes associated with treatment response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2dcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load realistic variant data\n",
    "variant_file = '../data/variants_realistic.csv'\n",
    "try:\n",
    "    variant_df = pd.read_csv(variant_file)\n",
    "    print(\"✅ Loaded realistic variant data\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: Realistic variant data not found at {variant_file}\")\n",
    "    print(\"Please run: python ../src/python/generate_realistic_pdx_data.py\")\n",
    "    raise\n",
    "\n",
    "print(f\"Variant data shape: {variant_df.shape}\")\n",
    "variant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44028873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differential expression analysis\n",
    "def find_response_associated_genes(expr_data, response_data, min_expression=1.0):\n",
    "    \"\"\"\n",
    "    Find genes associated with treatment response\n",
    "    \"\"\"\n",
    "    responders = response_data[response_data['IsResponder']].index\n",
    "    non_responders = response_data[~response_data['IsResponder']].index\n",
    "    \n",
    "    print(f\"Analyzing {len(responders)} responders vs {len(non_responders)} non-responders\")\n",
    "    \n",
    "    # Filter genes with sufficient expression\n",
    "    expressed_genes = expr_data.columns[expr_data.mean() >= min_expression]\n",
    "    print(f\"Analyzing {len(expressed_genes)} expressed genes\")\n",
    "    \n",
    "    gene_results = []\n",
    "    \n",
    "    for gene in expressed_genes:\n",
    "        responder_expr = expr_data.loc[responders, gene]\n",
    "        non_responder_expr = expr_data.loc[non_responders, gene]\n",
    "        \n",
    "        # Statistical test\n",
    "        if len(responder_expr) > 1 and len(non_responder_expr) > 1:\n",
    "            stat, pval = stats.mannwhitneyu(responder_expr, non_responder_expr, \n",
    "                                          alternative='two-sided')\n",
    "            \n",
    "            # Effect size (fold change)\n",
    "            mean_resp = responder_expr.mean()\n",
    "            mean_non_resp = non_responder_expr.mean()\n",
    "            fold_change = mean_resp / mean_non_resp if mean_non_resp > 0 else np.inf\n",
    "            log2_fc = np.log2(fold_change) if fold_change > 0 and fold_change != np.inf else 0\n",
    "            \n",
    "            gene_results.append({\n",
    "                'Gene': gene,\n",
    "                'ResponderMean': mean_resp,\n",
    "                'NonResponderMean': mean_non_resp,\n",
    "                'FoldChange': fold_change,\n",
    "                'Log2FC': log2_fc,\n",
    "                'PValue': pval,\n",
    "                'Significant': pval < 0.05\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(gene_results)\n",
    "    \n",
    "    # Adjust p-values (Bonferroni)\n",
    "    results_df['AdjustedPValue'] = results_df['PValue'] * len(results_df)\n",
    "    results_df['AdjustedPValue'] = results_df['AdjustedPValue'].clip(upper=1.0)\n",
    "    results_df['SignificantAdj'] = results_df['AdjustedPValue'] < 0.05\n",
    "    \n",
    "    return results_df.sort_values('PValue')\n",
    "\n",
    "# Run differential expression analysis\n",
    "de_results = find_response_associated_genes(expr_filtered, response_filtered)\n",
    "\n",
    "print(f\"\\nDifferential Expression Results:\")\n",
    "print(f\"Total genes tested: {len(de_results)}\")\n",
    "print(f\"Significant genes (p < 0.05): {de_results['Significant'].sum()}\")\n",
    "print(f\"Significant genes (adjusted p < 0.05): {de_results['SignificantAdj'].sum()}\")\n",
    "\n",
    "# Show top results\n",
    "print(\"\\nTop 10 genes associated with response:\")\n",
    "top_genes = de_results.head(10)\n",
    "for _, row in top_genes.iterrows():\n",
    "    print(f\"  {row['Gene']}: FC={row['FoldChange']:.2f}, p={row['PValue']:.3e}\")\n",
    "\n",
    "de_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d25089",
   "metadata": {},
   "source": [
    "## 4. Variant Analysis Integration\n",
    "\n",
    "Analyze how genomic variants contribute to treatment response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be115eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variant matrix\n",
    "def create_variant_matrix(variant_data, models):\n",
    "    \"\"\"\n",
    "    Create a binary matrix of variant presence/absence\n",
    "    \"\"\"\n",
    "    # Create binary matrix for each gene\n",
    "    variant_matrix = pd.DataFrame(index=models)\n",
    "    \n",
    "    for gene in variant_data['Gene'].unique():\n",
    "        # Models with variants in this gene\n",
    "        mutated_models = variant_data[variant_data['Gene'] == gene]['Model'].unique()\n",
    "        \n",
    "        # Create binary column\n",
    "        variant_matrix[f\"{gene}_mut\"] = 0\n",
    "        variant_matrix.loc[variant_matrix.index.isin(mutated_models), f\"{gene}_mut\"] = 1\n",
    "    \n",
    "    return variant_matrix\n",
    "\n",
    "# Create variant matrix for common models\n",
    "variant_matrix = create_variant_matrix(variant_df, common_models)\n",
    "print(f\"Variant matrix shape: {variant_matrix.shape}\")\n",
    "\n",
    "# Calculate variant-response associations\n",
    "def analyze_variant_response_association(variant_matrix, response_data):\n",
    "    \"\"\"\n",
    "    Analyze association between variants and treatment response\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for gene_col in variant_matrix.columns:\n",
    "        gene = gene_col.replace('_mut', '')\n",
    "        \n",
    "        # Get mutation status and response\n",
    "        mut_status = variant_matrix[gene_col]\n",
    "        responses = response_data.loc[mut_status.index, 'IsResponder']\n",
    "        \n",
    "        # Calculate response rates\n",
    "        mutated_models = mut_status[mut_status == 1].index\n",
    "        wild_type_models = mut_status[mut_status == 0].index\n",
    "        \n",
    "        if len(mutated_models) > 0 and len(wild_type_models) > 0:\n",
    "            mut_response_rate = responses[mutated_models].mean()\n",
    "            wt_response_rate = responses[wild_type_models].mean()\n",
    "            \n",
    "            # Fisher's exact test (approximated with chi-square)\n",
    "            from scipy.stats import chi2_contingency\n",
    "            \n",
    "            contingency = pd.crosstab(mut_status, responses)\n",
    "            if contingency.shape == (2, 2):\n",
    "                chi2, pval, _, _ = chi2_contingency(contingency)\n",
    "            else:\n",
    "                pval = 1.0\n",
    "            \n",
    "            results.append({\n",
    "                'Gene': gene,\n",
    "                'MutatedModels': len(mutated_models),\n",
    "                'WildTypeModels': len(wild_type_models),\n",
    "                'MutatedResponseRate': mut_response_rate,\n",
    "                'WildTypeResponseRate': wt_response_rate,\n",
    "                'ResponseDifference': mut_response_rate - wt_response_rate,\n",
    "                'PValue': pval\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('PValue')\n",
    "\n",
    "# Run variant-response analysis\n",
    "variant_response = analyze_variant_response_association(variant_matrix, response_filtered)\n",
    "\n",
    "print(f\"\\nVariant-Response Association Results:\")\n",
    "print(f\"Genes analyzed: {len(variant_response)}\")\n",
    "print(f\"Significant associations (p < 0.05): {(variant_response['PValue'] < 0.05).sum()}\")\n",
    "\n",
    "# Show top results\n",
    "print(\"\\nTop variant-response associations:\")\n",
    "for _, row in variant_response.head(5).iterrows():\n",
    "    print(f\"  {row['Gene']}: {row['ResponseDifference']:.3f} difference, p={row['PValue']:.3f}\")\n",
    "\n",
    "variant_response.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3981f8fc",
   "metadata": {},
   "source": [
    "## 5. Integrated Visualizations\n",
    "\n",
    "Create comprehensive visualizations combining all data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create integrated visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Response distribution\n",
    "response_counts = response_df['ResponseClass'].value_counts()\n",
    "axes[0,0].pie(response_counts.values, labels=response_counts.index, autopct='%1.1f%%')\n",
    "axes[0,0].set_title('Treatment Response Distribution')\n",
    "\n",
    "# 2. TGI distribution\n",
    "axes[0,1].hist(response_df['TGI'], bins=15, edgecolor='black', alpha=0.7)\n",
    "axes[0,1].axvline(response_df['TGI'].mean(), color='red', linestyle='--', label=f'Mean: {response_df[\"TGI\"].mean():.1f}%')\n",
    "axes[0,1].set_xlabel('Tumor Growth Inhibition (%)')\n",
    "axes[0,1].set_ylabel('Number of Models')\n",
    "axes[0,1].set_title('TGI Distribution')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# 3. Top differential genes\n",
    "top_de_genes = de_results.head(10)\n",
    "y_pos = range(len(top_de_genes))\n",
    "axes[0,2].barh(y_pos, top_de_genes['Log2FC'], \n",
    "               color=['red' if x > 0 else 'blue' for x in top_de_genes['Log2FC']])\n",
    "axes[0,2].set_yticks(y_pos)\n",
    "axes[0,2].set_yticklabels(top_de_genes['Gene'])\n",
    "axes[0,2].set_xlabel('Log2 Fold Change')\n",
    "axes[0,2].set_title('Top Differentially Expressed Genes')\n",
    "axes[0,2].axvline(0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# 4. Variant frequency\n",
    "if len(variant_df) > 0:\n",
    "    gene_counts = variant_df['Gene'].value_counts().head(10)\n",
    "    axes[1,0].barh(range(len(gene_counts)), gene_counts.values)\n",
    "    axes[1,0].set_yticks(range(len(gene_counts)))\n",
    "    axes[1,0].set_yticklabels(gene_counts.index)\n",
    "    axes[1,0].set_xlabel('Number of Models')\n",
    "    axes[1,0].set_title('Most Frequently Mutated Genes')\n",
    "else:\n",
    "    axes[1,0].text(0.5, 0.5, 'No variant data', ha='center', va='center')\n",
    "    axes[1,0].set_title('Variant Frequency')\n",
    "\n",
    "# 5. Variant-response association\n",
    "if len(variant_response) > 0:\n",
    "    top_var_resp = variant_response.head(8)\n",
    "    y_pos = range(len(top_var_resp))\n",
    "    colors = ['red' if x > 0 else 'blue' for x in top_var_resp['ResponseDifference']]\n",
    "    axes[1,1].barh(y_pos, top_var_resp['ResponseDifference'], color=colors)\n",
    "    axes[1,1].set_yticks(y_pos)\n",
    "    axes[1,1].set_yticklabels(top_var_resp['Gene'])\n",
    "    axes[1,1].set_xlabel('Response Rate Difference')\n",
    "    axes[1,1].set_title('Variant-Response Associations')\n",
    "    axes[1,1].axvline(0, color='black', linestyle='-', alpha=0.3)\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'No significant\\nassociations', ha='center', va='center')\n",
    "    axes[1,1].set_title('Variant-Response Associations')\n",
    "\n",
    "# 6. Expression vs Response correlation\n",
    "if len(de_results) > 0:\n",
    "    # Volcano plot\n",
    "    log_pvals = -np.log10(de_results['PValue'].clip(lower=1e-10))\n",
    "    scatter = axes[1,2].scatter(de_results['Log2FC'], log_pvals, \n",
    "                               c=de_results['Significant'], cmap='coolwarm', alpha=0.6)\n",
    "    axes[1,2].axhline(-np.log10(0.05), color='red', linestyle='--', alpha=0.5, label='p=0.05')\n",
    "    axes[1,2].axvline(0, color='black', linestyle='-', alpha=0.3)\n",
    "    axes[1,2].set_xlabel('Log2 Fold Change')\n",
    "    axes[1,2].set_ylabel('-Log10(p-value)')\n",
    "    axes[1,2].set_title('Expression Volcano Plot')\n",
    "    axes[1,2].legend()\n",
    "else:\n",
    "    axes[1,2].text(0.5, 0.5, 'No expression\\ndata available', ha='center', va='center')\n",
    "    axes[1,2].set_title('Expression Analysis')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/integrated_analysis_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Integrated analysis visualization saved to: ../results/integrated_analysis_summary.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f676dd",
   "metadata": {},
   "source": [
    "## 6. Principal Component Analysis\n",
    "\n",
    "Perform PCA on expression data to identify patterns related to response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc99f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on expression data\n",
    "if len(expr_filtered) > 0:\n",
    "    # Select top variable genes for PCA\n",
    "    gene_vars = expr_filtered.var().sort_values(ascending=False)\n",
    "    top_variable_genes = gene_vars.head(1000).index  # Top 1000 most variable genes\n",
    "    \n",
    "    # Standardize expression data\n",
    "    scaler = StandardScaler()\n",
    "    expr_scaled = scaler.fit_transform(expr_filtered[top_variable_genes])\n",
    "    \n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=min(10, len(expr_filtered)))\n",
    "    pca_result = pca.fit_transform(expr_scaled)\n",
    "    \n",
    "    # Create PCA DataFrame\n",
    "    pca_df = pd.DataFrame(pca_result, index=expr_filtered.index)\n",
    "    pca_df.columns = [f'PC{i+1}' for i in range(pca_result.shape[1])]\n",
    "    \n",
    "    # Add response information\n",
    "    pca_df = pca_df.join(response_filtered[['ResponseClass', 'TGI', 'IsResponder']])\n",
    "    \n",
    "    # Plot PCA results\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # PC1 vs PC2 colored by response\n",
    "    for response_class in pca_df['ResponseClass'].unique():\n",
    "        mask = pca_df['ResponseClass'] == response_class\n",
    "        axes[0].scatter(pca_df.loc[mask, 'PC1'], pca_df.loc[mask, 'PC2'], \n",
    "                       label=response_class, alpha=0.7, s=60)\n",
    "    axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "    axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "    axes[0].set_title('PCA: Response Classes')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # PC1 vs PC2 colored by TGI\n",
    "    scatter = axes[1].scatter(pca_df['PC1'], pca_df['PC2'], \n",
    "                             c=pca_df['TGI'], cmap='viridis', s=60, alpha=0.7)\n",
    "    plt.colorbar(scatter, ax=axes[1], label='TGI (%)')\n",
    "    axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "    axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%% variance)')\n",
    "    axes[1].set_title('PCA: TGI Values')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Explained variance\n",
    "    axes[2].bar(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "               pca.explained_variance_ratio_)\n",
    "    axes[2].set_xlabel('Principal Component')\n",
    "    axes[2].set_ylabel('Explained Variance Ratio')\n",
    "    axes[2].set_title('PCA Explained Variance')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/pca_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"PCA completed with {len(top_variable_genes)} genes\")\n",
    "    print(f\"First 3 PCs explain {pca.explained_variance_ratio_[:3].sum():.1%} of variance\")\n",
    "    \n",
    "else:\n",
    "    print(\"Insufficient expression data for PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a3fb97",
   "metadata": {},
   "source": [
    "## 7. Predictive Modeling\n",
    "\n",
    "Build a predictive model using integrated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd275cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "def prepare_integrated_features():\n",
    "    \"\"\"\n",
    "    Combine expression, variant, and other features for modeling\n",
    "    \"\"\"\n",
    "    features_df = pd.DataFrame(index=common_models)\n",
    "    \n",
    "    # Add top differential expression genes\n",
    "    if len(de_results) > 0:\n",
    "        top_genes = de_results.head(20)['Gene'].tolist()  # Top 20 DE genes\n",
    "        for gene in top_genes:\n",
    "            if gene in expr_filtered.columns:\n",
    "                features_df[f\"{gene}_expr\"] = expr_filtered[gene]\n",
    "    \n",
    "    # Add variant information\n",
    "    if len(variant_matrix) > 0:\n",
    "        # Add top variant-associated genes\n",
    "        top_variant_genes = variant_response.head(10)['Gene'].tolist()\n",
    "        for gene in top_variant_genes:\n",
    "            col_name = f\"{gene}_mut\"\n",
    "            if col_name in variant_matrix.columns:\n",
    "                features_df[col_name] = variant_matrix[col_name]\n",
    "    \n",
    "    # Add PCA components if available\n",
    "    if 'pca_df' in locals() and len(pca_df) > 0:\n",
    "        for i in range(min(5, pca_result.shape[1])):  # Top 5 PCs\n",
    "            features_df[f\"PC{i+1}\"] = pca_df[f\"PC{i+1}\"]\n",
    "    \n",
    "    return features_df\n",
    "\n",
    "# Prepare features\n",
    "features_df = prepare_integrated_features()\n",
    "print(f\"Integrated feature matrix: {features_df.shape}\")\n",
    "print(f\"Features: {list(features_df.columns)}\")\n",
    "\n",
    "# Remove features with too many missing values\n",
    "features_df = features_df.fillna(0)  # Fill missing values with 0\n",
    "\n",
    "if len(features_df) > 0 and len(features_df.columns) > 0:\n",
    "    # Build Random Forest model\n",
    "    X = features_df\n",
    "    y = response_filtered.loc[features_df.index, 'IsResponder']\n",
    "    \n",
    "    # Train model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X, y)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(rf_model, X, y, cv=min(5, len(X)), scoring='accuracy')\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nPredictive Model Results:\")\n",
    "    print(f\"Cross-validation accuracy: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
    "    print(f\"Training accuracy: {rf_model.score(X, y):.3f}\")\n",
    "    \n",
    "    print(f\"\\nTop 10 most important features:\")\n",
    "    for _, row in feature_importance.head(10).iterrows():\n",
    "        print(f\"  {row['Feature']}: {row['Importance']:.3f}\")\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(15)\n",
    "    plt.barh(range(len(top_features)), top_features['Importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Random Forest Feature Importance\\n(Top 15 Features)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Insufficient features for predictive modeling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64305ab5",
   "metadata": {},
   "source": [
    "## 8. Summary and Export Results\n",
    "\n",
    "Summarize the integrated analysis and export key results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc0277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary\n",
    "print(\"=\" * 60)\n",
    "print(\"PDX INTEGRATED ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n📊 DATA OVERVIEW:\")\n",
    "print(f\"  • Models analyzed: {len(common_models)}\")\n",
    "print(f\"  • Genes profiled: {expr_filtered.shape[1] if len(expr_filtered) > 0 else 0}\")\n",
    "print(f\"  • Variants detected: {len(variant_df) if len(variant_df) > 0 else 0}\")\n",
    "\n",
    "print(f\"\\n🎯 RESPONSE CHARACTERISTICS:\")\n",
    "if len(response_df) > 0:\n",
    "    print(f\"  • Mean TGI: {response_df['TGI'].mean():.1f}%\")\n",
    "    print(f\"  • Response rate: {response_df['IsResponder'].mean():.1%}\")\n",
    "    response_counts = response_df['ResponseClass'].value_counts()\n",
    "    for resp_class, count in response_counts.items():\n",
    "        print(f\"    - {resp_class}: {count} models ({count/len(response_df):.1%})\")\n",
    "\n",
    "print(f\"\\n🧬 GENE EXPRESSION FINDINGS:\")\n",
    "if len(de_results) > 0:\n",
    "    sig_genes = de_results['Significant'].sum()\n",
    "    print(f\"  • Significantly different genes: {sig_genes}\")\n",
    "    if sig_genes > 0:\n",
    "        print(f\"  • Top upregulated: {de_results[de_results['Log2FC'] > 0].head(1)['Gene'].iloc[0] if len(de_results[de_results['Log2FC'] > 0]) > 0 else 'None'}\")\n",
    "        print(f\"  • Top downregulated: {de_results[de_results['Log2FC'] < 0].head(1)['Gene'].iloc[0] if len(de_results[de_results['Log2FC'] < 0]) > 0 else 'None'}\")\n",
    "\n",
    "print(f\"\\n🔬 VARIANT ASSOCIATIONS:\")\n",
    "if len(variant_response) > 0:\n",
    "    sig_variants = (variant_response['PValue'] < 0.05).sum()\n",
    "    print(f\"  • Significant variant associations: {sig_variants}\")\n",
    "    if sig_variants > 0:\n",
    "        top_variant = variant_response.iloc[0]\n",
    "        print(f\"  • Top association: {top_variant['Gene']} (Δ = {top_variant['ResponseDifference']:.3f})\")\n",
    "\n",
    "print(f\"\\n🤖 PREDICTIVE MODEL:\")\n",
    "if 'cv_scores' in locals():\n",
    "    print(f\"  • Cross-validation accuracy: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
    "    print(f\"  • Features used: {len(features_df.columns)}\")\n",
    "    if len(feature_importance) > 0:\n",
    "        print(f\"  • Most important feature: {feature_importance.iloc[0]['Feature']}\")\n",
    "\n",
    "print(f\"\\n📁 OUTPUT FILES:\")\n",
    "print(f\"  • Integrated summary: ../results/integrated_analysis_summary.png\")\n",
    "if 'pca_df' in locals():\n",
    "    print(f\"  • PCA analysis: ../results/pca_analysis.png\")\n",
    "if 'feature_importance' in locals():\n",
    "    print(f\"  • Feature importance: ../results/feature_importance.png\")\n",
    "\n",
    "# Export key results\n",
    "if len(de_results) > 0:\n",
    "    de_results.to_csv('../results/differential_expression_results.csv', index=False)\n",
    "    print(f\"  • DE results: ../results/differential_expression_results.csv\")\n",
    "\n",
    "if len(variant_response) > 0:\n",
    "    variant_response.to_csv('../results/variant_response_associations.csv', index=False)\n",
    "    print(f\"  • Variant associations: ../results/variant_response_associations.csv\")\n",
    "\n",
    "response_df.to_csv('../results/response_metrics.csv', index=False)\n",
    "print(f\"  • Response metrics: ../results/response_metrics.csv\")\n",
    "\n",
    "print(f\"\\n✅ INTEGRATED ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
