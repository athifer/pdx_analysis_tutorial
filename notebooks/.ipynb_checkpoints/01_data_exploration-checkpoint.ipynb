{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bcc93bd",
   "metadata": {},
   "source": [
    "# PDX Analysis Tutorial - Data Exploration\n",
    "\n",
    "This notebook provides a comprehensive exploration of Patient-Derived Xenograft (PDX) datasets including tumor volumes, gene expression, and genomic variants.\n",
    "\n",
    "## Learning Objectives\n",
    "- Load and examine PDX datasets\n",
    "- Perform quality control checks\n",
    "- Generate descriptive statistics\n",
    "- Create initial visualizations\n",
    "- Identify data patterns and potential issues\n",
    "\n",
    "## Prerequisites\n",
    "- Python 3.7+\n",
    "- pandas, numpy, matplotlib, seaborn\n",
    "- Basic understanding of PDX research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b972bdb0",
   "metadata": {},
   "source": [
    "## 🚨 Environment Setup Issues?\n",
    "\n",
    "**If you encountered dependency conflicts or Jupyter issues, follow these steps first:**\n",
    "\n",
    "### Option 1: Quick Fix - Use Virtual Environment\n",
    "```bash\n",
    "# Create virtual environment\n",
    "python3 -m venv pdx_env\n",
    "source pdx_env/bin/activate\n",
    "\n",
    "# Install packages\n",
    "pip install --upgrade pip\n",
    "pip install pandas numpy matplotlib seaborn scipy scikit-learn jupyter\n",
    "\n",
    "# Start Jupyter\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "### Option 2: Use Conda (Recommended)\n",
    "```bash\n",
    "conda create -n pdx_analysis python=3.9\n",
    "conda activate pdx_analysis\n",
    "conda install pandas numpy matplotlib seaborn scipy scikit-learn jupyter -c conda-forge\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "### Option 3: Fix Jupyter Path Issue\n",
    "```bash\n",
    "# Check current Python\n",
    "which python3\n",
    "python3 --version\n",
    "\n",
    "# Reinstall Jupyter with current Python\n",
    "pip3 install --force-reinstall jupyter\n",
    "\n",
    "# Or use python -m to run Jupyter\n",
    "python3 -m jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3416a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Diagnostic - Run this cell first\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"=== ENVIRONMENT DIAGNOSTIC ===\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python path: {sys.path[:3]}...\")  # Show first 3 paths\n",
    "\n",
    "# Check if we can import required packages\n",
    "required_packages = ['pandas', 'numpy', 'matplotlib', 'seaborn']\n",
    "missing_packages = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"✅ {package}: Available\")\n",
    "    except ImportError:\n",
    "        print(f\"❌ {package}: Missing\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n⚠️  Missing packages: {missing_packages}\")\n",
    "    print(\"Run: pip install \" + \" \".join(missing_packages))\n",
    "else:\n",
    "    print(\"\\n🎉 All required packages are available!\")\n",
    "    \n",
    "# Check Jupyter installation\n",
    "try:\n",
    "    result = subprocess.run([sys.executable, '-m', 'jupyter', '--version'], \n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✅ Jupyter: Available\")\n",
    "        print(f\"   Version info: {result.stdout.strip()}\")\n",
    "    else:\n",
    "        print(f\"❌ Jupyter: Issue detected\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Jupyter: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77672a37",
   "metadata": {},
   "source": [
    "## 1. Load Required Libraries\n",
    "\n",
    "First, let's import the necessary Python libraries for data analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1f710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"✅ Libraries loaded successfully!\")\n",
    "print(f\"📊 Pandas version: {pd.__version__}\")\n",
    "print(f\"🔢 NumPy version: {np.__version__}\")\n",
    "print(f\"📈 Matplotlib version: {plt.matplotlib.__version__}\")\n",
    "print(f\"🎨 Seaborn version: {sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e2bb54",
   "metadata": {},
   "source": [
    "## 2. Load PDX Datasets\n",
    "\n",
    "Now let's load the Patient-Derived Xenograft datasets. We'll examine three key data types:\n",
    "- **Tumor volumes**: Growth measurements over time\n",
    "- **Gene expression**: RNA-seq data (TPM values)\n",
    "- **Genomic variants**: Mutation and copy number data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "data_dir = Path(\"../data\")\n",
    "\n",
    "# Load tumor volume data\n",
    "tumor_file = data_dir / \"tumor_volumes_mock.csv\"\n",
    "if tumor_file.exists():\n",
    "    tumor_data = pd.read_csv(tumor_file)\n",
    "    print(f\"✅ Loaded tumor volume data: {tumor_data.shape}\")\n",
    "else:\n",
    "    print(f\"❌ Tumor volume file not found: {tumor_file}\")\n",
    "    tumor_data = None\n",
    "\n",
    "# Load gene expression data\n",
    "expression_file = data_dir / \"expression_tpm_mock.csv\"\n",
    "if expression_file.exists():\n",
    "    expression_data = pd.read_csv(expression_file, index_col=0)\n",
    "    print(f\"✅ Loaded expression data: {expression_data.shape}\")\n",
    "else:\n",
    "    print(f\"❌ Expression file not found: {expression_file}\")\n",
    "    expression_data = None\n",
    "\n",
    "# Load variants data\n",
    "variants_file = data_dir / \"variants_mock.csv\"\n",
    "if variants_file.exists():\n",
    "    variants_data = pd.read_csv(variants_file)\n",
    "    print(f\"✅ Loaded variants data: {variants_data.shape}\")\n",
    "else:\n",
    "    print(f\"❌ Variants file not found: {variants_file}\")\n",
    "    variants_data = None\n",
    "\n",
    "# Load enhanced datasets if available\n",
    "enhanced_tumor_file = data_dir / \"tumor_volumes_enhanced.csv\"\n",
    "if enhanced_tumor_file.exists():\n",
    "    enhanced_tumor_data = pd.read_csv(enhanced_tumor_file)\n",
    "    print(f\"✅ Loaded enhanced tumor data: {enhanced_tumor_data.shape}\")\n",
    "    # Use enhanced data if available\n",
    "    tumor_data = enhanced_tumor_data\n",
    "else:\n",
    "    print(\"ℹ️ Enhanced tumor data not available, using basic mock data\")\n",
    "\n",
    "print(f\"\\n📁 Data directory contents:\")\n",
    "if data_dir.exists():\n",
    "    for file in data_dir.glob(\"*.csv\"):\n",
    "        size_mb = file.stat().st_size / (1024*1024)\n",
    "        print(f\"  - {file.name}: {size_mb:.2f} MB\")\n",
    "else:\n",
    "    print(\"  Data directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d19c137",
   "metadata": {},
   "source": [
    "## 3. Tumor Volume Data Exploration\n",
    "\n",
    "Let's examine the tumor growth data in detail - this is the core measurement in PDX studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tumor_data is not None:\n",
    "    print(\"=== TUMOR VOLUME DATA OVERVIEW ===\")\n",
    "    print(f\"📊 Dataset shape: {tumor_data.shape}\")\n",
    "    print(f\"📅 Timepoints: {tumor_data['Day'].nunique()} unique days\")\n",
    "    print(f\"🔬 Models: {tumor_data['Model'].nunique()} PDX models\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\n📋 First 10 rows:\")\n",
    "    display(tumor_data.head(10))\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"\\n❓ Missing values:\")\n",
    "    missing_summary = tumor_data.isnull().sum()\n",
    "    for col, missing in missing_summary.items():\n",
    "        if missing > 0:\n",
    "            print(f\"  - {col}: {missing} ({missing/len(tumor_data)*100:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"  - {col}: None\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\n📈 Volume statistics:\")\n",
    "    volume_stats = tumor_data['Volume_mm3'].describe()\n",
    "    for stat, value in volume_stats.items():\n",
    "        print(f\"  - {stat}: {value:.2f} mm³\")\n",
    "    \n",
    "    # Check data types\n",
    "    print(f\"\\n🔍 Data types:\")\n",
    "    for col, dtype in tumor_data.dtypes.items():\n",
    "        print(f\"  - {col}: {dtype}\")\n",
    "        \n",
    "    # Treatment groups\n",
    "    if 'Arm' in tumor_data.columns:\n",
    "        print(f\"\\n💊 Treatment groups:\")\n",
    "        arm_counts = tumor_data['Arm'].value_counts()\n",
    "        for arm, count in arm_counts.items():\n",
    "            print(f\"  - {arm}: {count} measurements\")\n",
    "else:\n",
    "    print(\"❌ No tumor volume data available for exploration\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
